version: '3'

name: "${PROJ_NAME}"
services:
  cardano-node:
    image: cardanocommunity/cardano-node:10.1.3
    init: true
    hostname: cardano-node
    environment:
      NETWORK: ${NETWORK}
      SOCKET: "${CNODE_HOME}/sockets/node.socket" 
      UPDATE_CHECK: "N"
    volumes:
      - node-db:/opt/cardano/cnode/db
      - node-ipc:/opt/cardano/cnode/sockets
      - node-cfg:/opt/cardano/cnode/files
      - ./scripts/:/scripts/
    restart: on-failure
    healthcheck:
      test: ["CMD-SHELL", "netstat -ntlp | grep 12798"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cardano-db-sync:
    image: ghcr.io/intersectmbo/cardano-db-sync:13.6.0.4
    hostname: cardano-db-sync
    environment:
      DISABLE_LEDGER: ${DISABLE_LEDGER}
      NETWORK: ${NETWORK:-mainnet}
      POSTGRES_HOST: postgress
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      RESTORE_SNAPSHOT: ${RESTORE_SNAPSHOT:-}
      RESTORE_RECREATE_DB: N
      DB_SYNC_CONFIG: ${DB_SYNC_CONFIG:-}
      #EXTRA_DB_SYNC_ARGS: ${EXTRA_DB_SYNC_ARGS:-}
    healthcheck:
      test: ["CMD-SHELL", "/scripts/lib/dbsync_healthcheck.sh"]
      interval: 60s
      timeout: 10s
    depends_on:
      # Depend on both services to be healthy before starting.
      cardano-node:
        condition: service_healthy
      postgress:
        condition: service_healthy
    volumes:
      - db-sync-data:/var/lib/cexplorer
      - node-ipc:/node-ipc
      - node-cfg:/opt/cardano/cnode/files
      - ./configs/dbsync:/dbsync-cfg
      - ./scripts/:/scripts/
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  postgress:
    image: postgres:16.4-bookworm
    hostname: postgress
    volumes:
      - postgresdb:/var/lib/postgresql/data
      - ./scripts/:/scripts/
    ports:
     - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      RPC_SCHEMA: ${RPC_SCHEMA}
    healthcheck:
      test:  ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 60s
      timeout: 5s
    command: postgres -c max_connections=200 -c maintenance_work_mem=2GB -c max_parallel_maintenance_workers=4 -c shared_buffers=6GB -c wal_level=minimal -c max_wal_senders=0 -c synchronous_commit=off
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  postgrest:
    image: postgrest/postgrest:v12.2.3
    hostname: postgrest
    depends_on:
      - postgress
    ports:
      - 8050:8050
    volumes:
      - ./scripts/:/scripts/
    environment:
      PGRST_DB_URI: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgress:${POSTGRES_PORT}/${POSTGRES_DB}
      PGRST_DB_ANON_ROLE: ${PGRST_DB_ANON_ROLE}
      PGRST_DB_SCHEMA: ${RPC_SCHEMA}
      PGRST_SERVER_PORT: 8050
      PGRST_OPENAPI_SERVER_PROXY_URI: http://0.0.0.0:8050
      PGRST_DB_MAX_ROWS: 1000
      PGRST_DB_AGGREGATES_ENABLED: true
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  portainer-agent:
    image: portainer/agent:latest
    environment:
      AGENT_CLUSTER_ADDR: portainer-agent
      AGENT_PORT: 9001
      LOG_LEVEL: DEBUG
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes

  portainer:
    image: portainer/portainer-ce:latest
    command: -H tcp://portainer-agent:9001 --tlsskipverify
    ports:
      - 9443:9443
      - 8000:8000
    volumes:
      - portainer-data:/data
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    depends_on:
      - portainer-agent

  haproxy:
    image: haproxy:3.1
    hostname: haproxy
    depends_on:
      - postgrest
    volumes:
      - ./configs/haproxy/:/usr/local/etc/haproxy/
      - ./scripts/:/scripts/
    ports:
      - 18053:18053
    healthcheck:
      test: ["CMD-SHELL", "haproxy -c -- /usr/local/etc/haproxy/haproxy.cfg"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: on-failure
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cron:
    build: .
    environment:
      NETWORK: ${NETWORK:-mainnet}
      POSTGRES_HOST: postgress
      POSTGRES_PORT: ${POSTGRES_PORT}
      PGDATABASE: ${POSTGRES_DB}
      PGUSER: ${POSTGRES_USER}
      PGPASSWORD: ${POSTGRES_PASSWORD}
      RPC_SCHEMA: ${RPC_SCHEMA}
    volumes:
      - ./scripts/cron:/etc/cron.d/
      - ./scripts:/scripts
    # Uncomment for persistent logs
    # - ./logs:/var/log
    restart: unless-stopped

volumes:
  node-db:
  node-ipc:
  node-cfg:
  db-sync-data:
  postgresdb:
  portainer-data:
